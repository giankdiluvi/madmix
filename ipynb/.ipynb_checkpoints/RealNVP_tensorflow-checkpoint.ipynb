{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a65ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, '../discrete_mixflows/')\n",
    "from discrete_mixflows import *\n",
    "from gibbs import *\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams[\"figure.figsize\"]=15,7.5\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa058052",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "########################\n",
    "# target specification #\n",
    "########################\n",
    "########################\n",
    "np.random.seed(2023)\n",
    "K1=10\n",
    "prbs=np.random.rand(K1)\n",
    "prbs=prbs/np.sum(prbs)\n",
    "def lp(x,axis=None):\n",
    "    # compute the univariate log joint and conditional target pmfs\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x    : (1,d) array with state values\n",
    "    #    axis : int, full conditional to calculate; returns joint if None\n",
    "    # outputs:\n",
    "    #   ext_lprb : if axis is None, (d,) array with log joint; else, (d,K1) array with d conditionals \n",
    "    \n",
    "    ext_lprb=np.log(np.repeat(prbs[:,np.newaxis],x.shape[1],axis=1).T)\n",
    "    if axis==None: return np.squeeze(ext_lprb[np.arange(0,x.shape[1]),x])\n",
    "    return ext_lprb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad61391",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "########################\n",
    "#   Concrete approx    #\n",
    "########################\n",
    "########################\n",
    "temperature=0.1\n",
    "ref_dist=tfp.distributions.RelaxedOneHotCategorical(temperature, probs=np.ones(K1)/K1) # uniform distribution\n",
    "target_dist=tfp.distributions.RelaxedOneHotCategorical(temperature, probs=prbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec69114",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "nvp = tfd.TransformedDistribution(\n",
    "    distribution=ref_dist,\n",
    "    bijector=tfb.RealNVP(\n",
    "        num_masked=6,\n",
    "        shift_and_log_scale_fn=tfb.real_nvp_default_template(\n",
    "            hidden_layers=[32, 32])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed506782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py:392: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  x = tf1.layers.dense(\n",
      "/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py:398: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  x = tf1.layers.dense(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampler: one-hot concrete to X\n",
    "np.sum(np.round(nvp.sample())*np.arange(1,11)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9304ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb33c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "def train_nf(trainable_distribution, n_iters=100, n_disp=10):\n",
    "    x_=tf.keras.Input(shape=(10,),dtype=tf.float32)\n",
    "    log_prob_=trainable_distribution.log_prob(x_)\n",
    "    model=tf.keras.Model(x_,log_prob_)\n",
    "    \n",
    "    model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                 loss=lambda _,log_prob: -log_prob)\n",
    "    \n",
    "    # display loss every n_disp iterations\n",
    "    epoch_callback=LambdaCallBack(\n",
    "        on_epoch_end=lambda n_iter, logs :\n",
    "            print('\\n Iteration {}/{}'.format(n_iter+1,n_iters,logs),\n",
    "                  '\\n\\t '+(': {:.4f}, '.join(logs.keys())+': {:.4f}'.format(*logs.values())))\n",
    "                  if n_iter%n_disp==0 else False\n",
    "    )\n",
    "    \n",
    "    X_data=dist.sample(1000)\n",
    "    \n",
    "    history=model.fit(\n",
    "        x=X_data,\n",
    "        y=np.zeros((X_data.shape[0],0),dtype=np.float32),\n",
    "        batch_size=X_data.shape[0],\n",
    "        epochs=n_iters,\n",
    "        validation_split=0,\n",
    "        shuffle=True,\n",
    "        verbose=False#,\n",
    "        #callbacks=[epoch_callback]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9f3aaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to share variable real_nvp_default_template/dense/kernel, but specified dtype float32 and found dtype float64.\n\noriginally defined at:\n  File \"/var/folders/k3/24b0dzl557v5m0_0658q2cxr0000gn/T/ipykernel_65722/541099623.py\", line 8, in <module>\n    shift_and_log_scale_fn=tfb.real_nvp_default_template(\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py\", line 409, in real_nvp_default_template\n    return tf1.make_template('real_nvp_default_template', _fn)\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py\", line 167, in make_template\n    return make_template_internal(\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py\", line 232, in make_template_internal\n    return EagerTemplate(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_nf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnvp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 5\u001b[0m, in \u001b[0;36mtrain_nf\u001b[0;34m(trainable_distribution, n_iters, n_disp)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_nf\u001b[39m(trainable_distribution, n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      4\u001b[0m     x_\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,),dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 5\u001b[0m     log_prob_\u001b[38;5;241m=\u001b[39m\u001b[43mtrainable_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(x_,log_prob_)\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[1;32m      9\u001b[0m                  loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m _,log_prob: \u001b[38;5;241m-\u001b[39mlog_prob)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/distribution.py:1287\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1276\u001b[0m   \u001b[38;5;124;03m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \n\u001b[1;32m   1278\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m      values of type `self.dtype`.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/distribution.py:1269\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[1;32m   1268\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_log_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_prob\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob(value, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:364\u001b[0m, in \u001b[0;36m_TransformedDistribution._log_prob\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    363\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector\u001b[38;5;241m.\u001b[39m_is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     log_prob, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_local_measure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_compat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;66;03m# TODO(b/197680518): Support base measure handling for non-injective\u001b[39;00m\n\u001b[1;32m    369\u001b[0m   \u001b[38;5;66;03m# bijectors.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:614\u001b[0m, in \u001b[0;36m_TransformedDistribution.experimental_local_measure\u001b[0;34m(self, y, backward_compat, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m distribution_kwargs, bijector_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs_split_fn(kwargs)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# For caching to work, it is imperative that the bijector is the first to\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# modify the input.\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbijector_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m event_ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector\u001b[38;5;241m.\u001b[39minverse_event_ndims(\n\u001b[1;32m    616\u001b[0m     tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(ps\u001b[38;5;241m.\u001b[39mrank_from_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_shape_tensor(),\n\u001b[1;32m    617\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_shape), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbijector_kwargs)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector\u001b[38;5;241m.\u001b[39m_is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1389\u001b[0m, in \u001b[0;36mBijector.inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minverse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1372\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m \n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;124;03m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1369\u001b[0m, in \u001b[0;36mBijector._call_inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inverse(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:347\u001b[0m, in \u001b[0;36mBijectorCache.inverse\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[38;5;241m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[38;5;241m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py:297\u001b[0m, in \u001b[0;36mRealNVP._inverse\u001b[0;34m(self, y, **condition_kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reverse_mask:\n\u001b[1;32m    295\u001b[0m   y0, y1 \u001b[38;5;241m=\u001b[39m y1, y0\n\u001b[0;32m--> 297\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bijector_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bijector_input_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcondition_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minverse(y1)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reverse_mask:\n\u001b[1;32m    301\u001b[0m   x1, y0 \u001b[38;5;241m=\u001b[39m y0, x1\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py:220\u001b[0m, in \u001b[0;36mRealNVP.__init__.<locals>._bijector_fn\u001b[0;34m(x0, input_depth, **condition_kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bijector_fn\u001b[39m(x0, input_depth, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcondition_kwargs):\n\u001b[0;32m--> 220\u001b[0m   shift, log_scale \u001b[38;5;241m=\u001b[39m \u001b[43mshift_and_log_scale_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcondition_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m   bijectors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    223\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shift \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py:693\u001b[0m, in \u001b[0;36mEagerTemplate.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_scope_context_manager:\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_template_store\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 693\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m   \u001b[38;5;66;03m# The scope was not created at construction time, so create it here.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m   \u001b[38;5;66;03m# Subsequent calls should reuse variables.\u001b[39;00m\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m variable_scope\u001b[38;5;241m.\u001b[39mvariable_scope(\n\u001b[1;32m    698\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name,\n\u001b[1;32m    699\u001b[0m       custom_getter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_getter) \u001b[38;5;28;01mas\u001b[39;00m vs:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py:627\u001b[0m, in \u001b[0;36mEagerTemplate._call_func\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m trainable_at_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_template_store\u001b[38;5;241m.\u001b[39mtrainable_variables()\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables_created:\n\u001b[0;32m--> 627\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m   \u001b[38;5;66;03m# The first time we run, restore variables if necessary (via\u001b[39;00m\n\u001b[1;32m    630\u001b[0m   \u001b[38;5;66;03m# Trackable).\u001b[39;00m\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trackable_util\u001b[38;5;241m.\u001b[39mcapture_dependencies(template\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py:392\u001b[0m, in \u001b[0;36mreal_nvp_default_template.<locals>._fn\u001b[0;34m(x, output_units, **condition_kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m   reshape_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m units \u001b[38;5;129;01min\u001b[39;00m hidden_layers:\n\u001b[0;32m--> 392\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mtf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m      \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m      \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=keyword-arg-before-vararg\u001b[39;49;00m\n\u001b[1;32m    397\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m x \u001b[38;5;241m=\u001b[39m tf1\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mdense(\n\u001b[1;32m    399\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    400\u001b[0m     units\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shift_only \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m output_units,\n\u001b[1;32m    401\u001b[0m     activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;241m*\u001b[39margs,  \u001b[38;5;66;03m# pylint: disable=keyword-arg-before-vararg\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shift_only:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/legacy_tf_layers/core.py:274\u001b[0m, in \u001b[0;36mdense\u001b[0;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    252\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.layers.dense` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `tf.keras.layers.Dense` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    256\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    258\u001b[0m layer \u001b[38;5;241m=\u001b[39m Dense(\n\u001b[1;32m    259\u001b[0m     units,\n\u001b[1;32m    260\u001b[0m     activation\u001b[38;5;241m=\u001b[39mactivation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     _reuse\u001b[38;5;241m=\u001b[39mreuse,\n\u001b[1;32m    273\u001b[0m )\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/legacy_tf_layers/base.py:622\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscope\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scope\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# Actually call layer\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;66;03m# Update global default collections.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m     _add_elements_to_collection(\n\u001b[1;32m    627\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdates, tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39mUPDATE_OPS\n\u001b[1;32m    628\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:909\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    907\u001b[0m     dtype_str \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    908\u001b[0m     found_type_str \u001b[38;5;241m=\u001b[39m found_var\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 909\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to share variable \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but specified dtype \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and found dtype \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    911\u001b[0m                      (name, dtype_str, found_type_str))\n\u001b[1;32m    912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m found_var\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# The code below handles only the case of creating a new variable.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to share variable real_nvp_default_template/dense/kernel, but specified dtype float32 and found dtype float64.\n\noriginally defined at:\n  File \"/var/folders/k3/24b0dzl557v5m0_0658q2cxr0000gn/T/ipykernel_65722/541099623.py\", line 8, in <module>\n    shift_and_log_scale_fn=tfb.real_nvp_default_template(\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/real_nvp.py\", line 409, in real_nvp_default_template\n    return tf1.make_template('real_nvp_default_template', _fn)\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py\", line 167, in make_template\n    return make_template_internal(\n  File \"/Users/giankdiluvi/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/template.py\", line 232, in make_template_internal\n    return EagerTemplate(\n"
     ]
    }
   ],
   "source": [
    "history=train_nf(nvp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487940c3",
   "metadata": {},
   "source": [
    "## ipynb implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b76865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer,Dense\n",
    "\n",
    "class NN(Layer):\n",
    "    \"\"\"\n",
    "    Neural Network Architecture for calcualting s and t for Real-NVP\n",
    "    \n",
    "    :param input_shape: shape of the data coming in the layer\n",
    "    :param hidden_units: Python list-like of non-negative integers, specifying the number of units in each hidden layer.\n",
    "    :param activation: Activation of the hidden units\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_hidden=[512, 512], activation=\"relu\", name=\"nn\"):\n",
    "        super(NN, self).__init__(name=\"nn\")\n",
    "        layer_list = []\n",
    "        for i, hidden in enumerate(n_hidden):\n",
    "            layer_list.append(Dense(hidden, activation=activation))\n",
    "        self.layer_list = layer_list\n",
    "        self.log_s_layer = Dense(input_shape, activation=\"tanh\", name='log_s')\n",
    "        self.t_layer = Dense(input_shape, name='t')\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.layer_list:\n",
    "            y = layer(y)\n",
    "        log_s = self.log_s_layer(y)\n",
    "        t = self.t_layer(y)\n",
    "        return log_s, t\n",
    "\n",
    "class myRealNVP(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Implementation of a Real-NVP for Denisty Estimation. L. Dinh “Density estimation using Real NVP,” 2016.\n",
    "    This implementation only works for 1D arrays.\n",
    "    :param input_shape: shape of the data coming in the layer\n",
    "    :param hidden_units: Python list-like of non-negative integers, specifying the number of units in each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, n_hidden=[512, 512], forward_min_event_ndims=1, validate_args: bool = False, name=\"real_nvp\"):\n",
    "        super(myRealNVP, self).__init__(\n",
    "            validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "        )\n",
    "\n",
    "        assert input_shape % 2 == 0\n",
    "        input_shape = input_shape // 2\n",
    "        nn_layer = NN(input_shape, n_hidden)\n",
    "        x = tf.keras.Input(input_shape)\n",
    "        log_s, t = nn_layer(x)\n",
    "        self.nn = Model(x, [log_s, t], name=\"nn\")\n",
    "        \n",
    "    def _bijector_fn(self, x):\n",
    "        log_s, t = self.nn(x)\n",
    "        return tfb.affine_scalar.AffineScalar(shift=t, log_scale=log_s)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x_a, x_b = tf.split(x, 2, axis=-1)\n",
    "        y_b = x_b\n",
    "        y_a = self._bijector_fn(x_b).forward(x_a)\n",
    "        y = tf.concat([y_a, y_b], axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y_a, y_b = tf.split(y, 2, axis=-1)\n",
    "        x_b = y_b\n",
    "        x_a = self._bijector_fn(y_b).inverse(y_a)\n",
    "        x = tf.concat([x_a, x_b], axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        x_a, x_b = tf.split(x, 2, axis=-1)\n",
    "        return self._bijector_fn(x_b).forward_log_det_jacobian(x_a, event_ndims=1)\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        y_a, y_b = tf.split(y, 2, axis=-1)\n",
    "        return self._bijector_fn(y_b).inverse_log_det_jacobian(y_a, event_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e243afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain bijectors\n",
    "# from https://github.com/LukasRinder/normalizing-flows/blob/master/experiments/real-nvp/real_nvp_uci.ipynb\n",
    "\n",
    "bijectors = []\n",
    "layers=2\n",
    "for i in range(layers):\n",
    "    bijectors.append(myRealNVP(input_shape=4))\n",
    "    #bijectors.append(tfp.bijectors.Permute(permutation))\n",
    "\n",
    "bijector = tfb.Chain(bijectors=list(reversed(bijectors)), name='chain_of_real_nvp')\n",
    "\n",
    "flow = tfd.TransformedDistribution(\n",
    "    distribution=ref_dist,\n",
    "    bijector=bijector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc506770",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'nn' (type NN).\n\nInput 0 of layer \"dense_4\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (5,)\n\nCall arguments received by layer 'nn' (type NN):\n  • x=tf.Tensor(shape=(5,), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:338\u001b[0m, in \u001b[0;36m_TransformedDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_broadcast_distribution_batch_shape()\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    334\u001b[0m     sample_shape\u001b[38;5;241m=\u001b[39msample_shape, seed\u001b[38;5;241m=\u001b[39mseed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdistribution_kwargs)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Apply the bijector's forward transformation. For caching to\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# work, it is imperative that this is the last modification to the\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# returned result.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbijector_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1326\u001b[0m, in \u001b[0;36mBijector.forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1311\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the forward `Bijector` evaluation, i.e., X = g(Y).\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;124;03m    NotImplementedError: if `_forward` is not implemented.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1308\u001b[0m, in \u001b[0;36mBijector._call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:334\u001b[0m, in \u001b[0;36mBijectorCache.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    324\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the 'forward' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    The output of the bijector's `_forward` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[38;5;241m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[38;5;241m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/composition.py:605\u001b[0m, in \u001b[0;36mComposition._forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 605\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_walk_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/composition.py:290\u001b[0m, in \u001b[0;36mComposition._call_walk_forward\u001b[0;34m(self, step_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(nest_util\u001b[38;5;241m.\u001b[39mcoerce_structure(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_min_event_ndims, x)\n\u001b[1;32m    287\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 290\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_walk_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m packed_args \u001b[38;5;241m=\u001b[39m pack_structs_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_min_event_ndims, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/chain.py:143\u001b[0m, in \u001b[0;36m_Chain._walk_forward\u001b[0;34m(self, step_fn, x, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"Applies `transform_fn` to `x` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bij \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bijectors):\n\u001b[0;32m--> 143\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/composition.py:606\u001b[0m, in \u001b[0;36mComposition._forward.<locals>.<lambda>\u001b[0;34m(b, x, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    605\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_walk_forward(\n\u001b[0;32m--> 606\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m b, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    607\u001b[0m       x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1326\u001b[0m, in \u001b[0;36mBijector.forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1311\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the forward `Bijector` evaluation, i.e., X = g(Y).\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;124;03m    NotImplementedError: if `_forward` is not implemented.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/bijectors/bijector.py:1308\u001b[0m, in \u001b[0;36mBijector._call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:334\u001b[0m, in \u001b[0;36mBijectorCache.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    324\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the 'forward' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    The output of the bijector's `_forward` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[38;5;241m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[38;5;241m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[38;5;124;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [12], line 55\u001b[0m, in \u001b[0;36mmyRealNVP._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m x_a, x_b \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msplit(x, \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m y_b \u001b[38;5;241m=\u001b[39m x_b\n\u001b[0;32m---> 55\u001b[0m y_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bijector_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mforward(x_a)\n\u001b[1;32m     56\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([y_a, y_b], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "Cell \u001b[0;32mIn [12], line 49\u001b[0m, in \u001b[0;36mmyRealNVP._bijector_fn\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bijector_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 49\u001b[0m     log_s, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfb\u001b[38;5;241m.\u001b[39maffine_scalar\u001b[38;5;241m.\u001b[39mAffineScalar(shift\u001b[38;5;241m=\u001b[39mt, log_scale\u001b[38;5;241m=\u001b[39mlog_s)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn [12], line 23\u001b[0m, in \u001b[0;36mNN.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_list:\n\u001b[0;32m---> 23\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m log_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_s_layer(y)\n\u001b[1;32m     25\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_layer(y)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'nn' (type NN).\n\nInput 0 of layer \"dense_4\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (5,)\n\nCall arguments received by layer 'nn' (type NN):\n  • x=tf.Tensor(shape=(5,), dtype=float32)"
     ]
    }
   ],
   "source": [
    "flow.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
