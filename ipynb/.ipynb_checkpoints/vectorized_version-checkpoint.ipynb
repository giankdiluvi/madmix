{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a7df29",
   "metadata": {},
   "source": [
    "# Deterministic slice flows\n",
    "\n",
    "Vectorized version of the functions in `density_evaluation`.\n",
    "\n",
    "Consider a target density $\\pi(x_{1:M},u_{1:M})=p(x_{1:M})1_{[0,1]}(u_{1:M})$ \n",
    "where we have access to the full conditionals $p_m$ \n",
    "and let $F_m,Q_m$ be the cdf and quantile functions of $p_m$.\n",
    "We approximate $\\pi$ with a variational ergodic flow\n",
    "$$\n",
    "    q_N=\\frac{1}{N}\\sum_{n=0}^N T^nq_0,\n",
    "$$\n",
    "where $q_0$ is a reference distribution and\n",
    "$T=T_m\\circ\\cdots\\circ T_1$ mimics Gibbs sampling, i.e.,\n",
    "each map $T_m$ updates only $(x_m,u_m)\\mapsto(x_m',u_m')$.\n",
    "Specifically,\n",
    "$$\n",
    "\\begin{pmatrix}x_m'\\\\u_m'\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "    Q_m(\\rho(x_m,u_m)+\\xi\\mod 1)\\\\ \n",
    "    \\frac{1}{p_m(x_m')}((\\rho(x_m,u_m)+\\xi\\mod 1)-F(x_m'))\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "where $\\rho(x,u)=F_m(x-1)+up_m(x)$ converts to proportions and $F_m(0)=0$ by convention.\n",
    "\n",
    "In the notes,\n",
    "I showed that the variational density can be evaluated in closed form\n",
    "since the Jacobians of the continuous restriction correspond to density ratios. Specifically,\n",
    "$$\n",
    "    q_N(x_{1:M},u_{1:M})\n",
    "    =\\frac{1}{N}\\sum_{n=0}^{N-1}\n",
    "    q_0(T^{-n}(x_{1:M},u_{1:M})\n",
    "    \\prod_{j=1}^n\\prod_{m=1}^M \\frac{p_m(T^{-j+1}(x_{1:M},u_{1:M}))}{p_m(T^{-j}(x_{1:M},u_{1:M}))}.\n",
    "$$\n",
    "\n",
    "First we define all the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f01ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams[\"figure.figsize\"]=15,7.5\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b177ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "# variational approximation functions\n",
    "########################################\n",
    "########################################\n",
    "def lqN(x,u,N,lq0,lp,xi=np.pi/16):\n",
    "    # evaluate variational log likelihood log qN(x,u)\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x         : (M,d) array, states of xm\n",
    "    #    u         : (M,d) array, values of um\n",
    "    #    N         : int, variational parameter; max number of applications of T\n",
    "    #    lq0       : function, reference log likelihood (vectorized)\n",
    "    #    lp        : function, target log likelihood (vectorized)\n",
    "    #    xi        : scalar, uniform shift\n",
    "    #\n",
    "    # outputs:\n",
    "    #   logqN(x,u) : (d,) array, likelihood at each datum x_i\n",
    "    \n",
    "    if N==1: return lq0(x,u)\n",
    "    w=np.zeros((N,x.shape[1]))\n",
    "    w[0,:]=lq0(x,u)\n",
    "    LJ=np.zeros(x.shape[1])\n",
    "    for n in range(N-1):\n",
    "        sprbs=np.sum(lp(x),axis=0)\n",
    "        x,u=flow(x,u,1,lp,xi,direction='bwd')\n",
    "        LJ=LJ+sprbs-np.sum(lp(x),axis=0)\n",
    "        w[n+1,:]=lq0(x,u)+LJ\n",
    "    # end for\n",
    "    return LogSumExp(w)-np.log(N)\n",
    "\n",
    "def randqN(size,N,randq0):\n",
    "    if N==1: return randq0(size)\n",
    "    K=np.random.randint(low=0,high=N,size=size)\n",
    "    x,u=randq0(size)\n",
    "    for i in range(size): \n",
    "        tx,tu = flow(np.atleast_1d(x[i,...]),np.atleast_1d(u[i,...]),steps=K[i],lp=lp,xi=xi,direction='fwd')\n",
    "        x[i,...]=tx\n",
    "        u[i,...]=tu\n",
    "    return x,u\n",
    "    \n",
    "\n",
    "\n",
    "########################################\n",
    "########################################\n",
    "# flow functions\n",
    "########################################\n",
    "########################################\n",
    "def flow(x,u,steps,lp,xi=np.pi/16,direction='fwd'):\n",
    "    # compute T^n(x,u)\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x         : (M,d) array, initial states of x\n",
    "    #    u         : (M,d) array, initial values of u\n",
    "    #    steps     : int, number of applications of T, n\n",
    "    #    lp        : function, posterior and conditional pmf\n",
    "    #    xi        : scalar, uniform shift\n",
    "    #    direction : string, one of 'fwd' (forward map) or 'bwd' (backward map)\n",
    "    #\n",
    "    # outputs:\n",
    "    #   x' : (M,d) array, updated states x'\n",
    "    #   u' : (M,d) array, updated values u'\n",
    "    \n",
    "    M=x.shape[0]\n",
    "    if steps==0: return x,u\n",
    "    for t in range(steps):\n",
    "        for m in range(M):\n",
    "            m_idx = m if direction=='fwd'else M-m-1 # if in reverse, update starting from the end\n",
    "            tmp_prbs=np.atleast_1d(np.exp(lp(x,axis=m_idx)))\n",
    "            tmp_prbs=tmp_prbs/np.sum(tmp_prbs,axis=1)[:,np.newaxis]\n",
    "            tx,tu=Tm(x[m_idx,:],u[m_idx,:],tmp_prbs,xi,direction=direction)\n",
    "            x[m_idx,:]=tx\n",
    "            u[m_idx,:]=tu\n",
    "        # end for\n",
    "    # end for\n",
    "    return x,u\n",
    "        \n",
    "    \n",
    "def Tm(x,u,prbs,xi=np.pi/16,direction='fwd'):\n",
    "    # compute Tm(x,u)\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x         : (d,) array, states of xm\n",
    "    #    u         : (d,) array, values of um\n",
    "    #    prbs      : (d,Km) array, probabilities of Xm|X-m for each of the d xm's\n",
    "    #    xi        : scalar, uniform shift\n",
    "    #    direction : string, one of 'fwd' (forward map) or 'bwd' (backward map)\n",
    "    #\n",
    "    # outputs:\n",
    "    #   xp : (d,) array, updated states xm'\n",
    "    #   up : (d,) array, updated values um'\n",
    "    \n",
    "    if direction=='bwd': xi=-xi\n",
    "    p=getp(x,u,prbs,xi)\n",
    "    xp=quantile(p,prbs)\n",
    "    up=(p-cdf(xp-1,prbs))/prbs[np.arange(0,xp.shape[0]),xp]\n",
    "    return xp,up\n",
    "\n",
    "\n",
    "def getp(x,u,prbs,xi=np.pi/16):\n",
    "    # get proportion from current pair (xm,um)\n",
    "    # equivalent to rho+xi mod 1 in paper\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x         : (d,) array, states of xm\n",
    "    #    u         : (d,) array, values of um\n",
    "    #    prbs      : (d,Km) array, probabilities of Xm|X-m for each of the d xm's\n",
    "    #    xi        : scalar, uniform shift\n",
    "    #\n",
    "    # outputs:\n",
    "    #   p' : (d,) array, proportion and shifted states p'\n",
    "    \n",
    "    p=u*prbs[np.arange(0,x.shape[0]),x]\n",
    "    F=np.cumsum(prbs,axis=1) # cdf\n",
    "    p[x>0]=p[x>0]+np.squeeze(F[np.where(x>0),x[x>0]-1]) # vectorized \"+prbs[:x] if x>0\"\n",
    "    return (p+xi)%1\n",
    "    \n",
    "    \n",
    "########################################\n",
    "########################################\n",
    "# inference\n",
    "########################################\n",
    "########################################\n",
    "def elbo(B,lp,N,M,lq0,randqN,randq0,xi=np.pi/16):\n",
    "    tx,tu=randqN(B,N,randq0)\n",
    "    elbos=np.zeros(B)\n",
    "    for b in range(B): elbos[b]=lp(np.atleast_1d(tx[b]))-lqN(np.atleast_1d(tx[b]),np.atleast_1d(tu[b]),N,lq0,lp,xi)\n",
    "    return np.mean(elbos)\n",
    "        \n",
    "\n",
    "########################################\n",
    "########################################\n",
    "# auxiliary functions\n",
    "########################################\n",
    "########################################\n",
    "def LogSumExp(w):\n",
    "    # LogSumExp trick\n",
    "    #\n",
    "    # inputs:\n",
    "    #    w : (N,d) array, exponents\n",
    "    #\n",
    "    # outputs:\n",
    "    #    w' : (N,d) array, log(sum(exp(w)))\n",
    "    wmax = np.amax(w,axis=0)\n",
    "    return wmax + np.log(np.sum(np.exp(w-wmax[np.newaxis,:]),axis=0))\n",
    "\n",
    "def cdf(x,prbs): \n",
    "    # cdf of x given prbs (vectorized): F(x)\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x    : (d,) array, states of xm\n",
    "    #    prbs : (d,Km) array, probabilities of Xm|X-m for each of the d xm's\n",
    "    #\n",
    "    # outputs:\n",
    "    #   F(x) : (d,) array, cdf of X at each xi (F(x)_i=F(x_i))\n",
    "    \n",
    "    F=np.hstack((np.zeros((prbs.shape[0],1)),np.cumsum(prbs,axis=1))) # adding 0's so F(0)=0\n",
    "    return F[np.arange(0,x.shape[0]),x+1]\n",
    "\n",
    "def quantile(u,prbs): \n",
    "    # quantile function of u given prbs (badly vectorized)\n",
    "    # via scipy stats, couldn't implement in native numpy\n",
    "    #\n",
    "    # inputs:\n",
    "    #    u    : (d,) array, values of um\n",
    "    #    prbs : (d,Km) array, probabilities of Xm|X-m for each of the d xm's\n",
    "    #\n",
    "    # outputs:\n",
    "    #   Q(x) : (d,) array, quantile of X at each ui (Q(u)_i=Q(u_i))\n",
    "    quants=np.zeros(u.shape[0])\n",
    "    for d in range(u.shape[0]):\n",
    "        tmprv=stats.rv_discrete(values=(np.arange(0,prbs.shape[1]), prbs[d,:]))\n",
    "        quants[d]=tmprv.ppf(u[d])\n",
    "    return quants.astype(int)\n",
    "\n",
    "\n",
    "def gen_lp(prbs):\n",
    "    # generate an iterable lp function given probs array prbs\n",
    "    #\n",
    "    # inputs:\n",
    "    #    prbs : (K1,...,KM) array, probabilities\n",
    "    #\n",
    "    # outputs:\n",
    "    #   my_lp : function, obtains joint and conditional probabilities\n",
    "    #           my_lp(x)      -> joint at states x\n",
    "    #           my_lp(x,axis) -> conditional of x_axis given x_{-axis}\n",
    "    \n",
    "    def my_lp(x,axis=None):\n",
    "        if axis==None: return prbs[tuple(x)] # evaluate lp(x)\n",
    "        # else return prbs[x_1,x_2,...,x_{m-1},:,x_{m+1},...,x_M] with m=axis\n",
    "        tmp_prbs=np.ones(prbs.shape[axis]) # init uniform\n",
    "        tmp_x=np.copy(x)\n",
    "        for i in range(prbs.shape[axis]):\n",
    "            tmp_x[axis]=i\n",
    "            tmp_prbs[i]=prbs[tuple(tmp_x)] \n",
    "        # end for\n",
    "        return tmp_prbs\n",
    "    return my_lp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e9eba4",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0957664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the distribution\n",
    "np.random.seed(2022)\n",
    "K1=4\n",
    "prbs=np.random.rand(K1)\n",
    "prbs=prbs/np.sum(prbs)\n",
    "def lp(x,axis=None):\n",
    "    # compute the univariate log joint and conditional target pmfs\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x    : (M,d) array with state values\n",
    "    #    axis : int, variable to condition on; returns joint if None\n",
    "    # outputs:\n",
    "    #   ext_lprb : if axis is None, (d,) array with log joint; else, (d,K1) array with d conditionals \n",
    "    \n",
    "    ext_lprb=np.log(np.repeat(prbs[:,np.newaxis],x.shape[1],axis=1).T)\n",
    "    if axis==None: return ext_lprb[np.arange(0,x.shape[1]),x]\n",
    "    return ext_lprb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d42d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3]] [[0.5  0.99]]\n",
      "[[3 3]] [[0.602923  0.4992882]]\n",
      "[[0 3]] [[0.5  0.99]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([0,3],dtype=int).reshape(1,2)\n",
    "u=np.array([0.5,0.99]).reshape(1,2)\n",
    "print(x,u)\n",
    "x,u=flow(x,u,10,lp,direction='fwd')\n",
    "print(x,u)\n",
    "x,u=flow(x,u,10,lp,direction='bwd')\n",
    "print(x,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bafee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lq0 = lambda x,u : np.log(1/K1)*np.ones(x.shape[1])\n",
    "def randq0(size): return np.random.randint(0,prbs.shape[0],size),np.random.rand(size)\n",
    "xi=np.pi/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73110f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tm2(x,u,prbs,xi=np.pi/16,direction='fwd'):\n",
    "    if direction=='bwd': xi=-xi\n",
    "    p=getp2(x,u,prbs,xi)\n",
    "    xp=quantile2(p,prbs)\n",
    "    up=(p-cdf2(xp-1,prbs))/prbs[xp]\n",
    "    return xp,up\n",
    "\n",
    "\n",
    "def getp2(x,u,prbs,xi=np.pi/16):\n",
    "    p=u*prbs[x]\n",
    "    if x>0:  p+=np.sum(prbs[:x])\n",
    "    return (p+xi)%1\n",
    "\n",
    "def cdf2(x,prbs): return np.sum(prbs[:(x+1)])\n",
    "def quantile2(u,prbs): return np.argmax(np.cumsum(prbs)>u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45a65098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqN(x,u,N,lq0,lp,xi=np.pi/16):\n",
    "    # evaluate variational log likelihood log qN(x,u)\n",
    "    #\n",
    "    # inputs:\n",
    "    #    x         : (M,d) array, states of xm\n",
    "    #    u         : (M,d) array, values of um\n",
    "    #    N         : int, variational parameter; max number of applications of T\n",
    "    #    lq0       : function, reference log likelihood (vectorized)\n",
    "    #    lp        : function, target log likelihood (vectorized)\n",
    "    #    xi        : scalar, uniform shift\n",
    "    #\n",
    "    # outputs:\n",
    "    #   logqN(x,u) : (d,) array, likelihood at each datum x_i\n",
    "    \n",
    "    if N==1: return lq0(x,u)\n",
    "    w=np.zeros((N,x.shape[1]))\n",
    "    w[0,:]=lq0(x,u)\n",
    "    LJ=np.zeros(x.shape[1])\n",
    "    for n in range(N-1):\n",
    "        sprbs=np.sum(lp(x),axis=0)\n",
    "        x,u=flow(x,u,1,lp,xi,direction='bwd')\n",
    "        LJ=LJ+sprbs-np.sum(lp(x),axis=0)\n",
    "        w[n+1,:]=lq0(x,u)+LJ\n",
    "    # end for\n",
    "    return LogSumExp(w)-np.log(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf50127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66930746, -0.24289398])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "N=10\n",
    "\n",
    "x=np.array([[1,1]],dtype=int)\n",
    "u=np.array([[0.5,0.999]])\n",
    "\n",
    "lqN(x,u,N,lq0,lp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
