{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244ae3d5",
   "metadata": {},
   "source": [
    "# Deterministic slice flows\n",
    "\n",
    "Consider a target density $\\pi(x_{1:M},u_{1:M})=p(x_{1:M})1_{[0,1]}(u_{1:M})$ \n",
    "where we have access to the full conditionals $p_m$ \n",
    "and let $F_m,Q_m$ be the cdf and quantile functions of $p_m$.\n",
    "We approximate $\\pi$ with a variational ergodic flow\n",
    "$$\n",
    "    q_N=\\frac{1}{N}\\sum_{n=0}^N T^nq_0,\n",
    "$$\n",
    "where $q_0$ is a reference distribution and\n",
    "$T=T_m\\circ\\cdots\\circ T_1$ mimics Gibbs sampling, i.e.,\n",
    "each map $T_m$ updates only $(x_m,u_m)\\mapsto(x_m',u_m')$.\n",
    "Specifically,\n",
    "$$\n",
    "\\begin{pmatrix}x_m'\\\\u_m'\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "    Q_m(\\rho(x_m,u_m)+\\xi\\mod 1)\\\\ \n",
    "    \\frac{1}{p_m(x_m')}((\\rho(x_m,u_m)+\\xi\\mod 1)-F(x_m'))\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "where $\\rho(x,u)=F_m(x-1)+up_m(x)$ converts to proportions and $F_m(0)=0$ by convention.\n",
    "\n",
    "In the notes,\n",
    "I showed that the variational density can be evaluated in closed form\n",
    "since the Jacobians of the continuous restriction correspond to density ratios. Specifically,\n",
    "$$\n",
    "    q_N(x_{1:M},u_{1:M})\n",
    "    =\\frac{1}{N}\\sum_{n=0}^{N-1}\n",
    "    \\frac{q_0(T^{-n}(x_{1:M},u_{1:M})}\n",
    "    {\\prod_{j=1}^n\\prod_{m=1}^M \\frac{p_m(x_m)}{p(T^{-j}(x_{1:M},u_{1:M}))}}.\n",
    "$$\n",
    "\n",
    "First we define all the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3848e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams[\"figure.figsize\"]=15,7.5\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246cabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "# variational approximation functions\n",
    "########################################\n",
    "########################################\n",
    "def lqN(x,u,N,lq0,prbs,xi=np.pi/16):\n",
    "    if N==1: return lq0(x,u)\n",
    "    sprbs=np.sum(prbs[x])\n",
    "    w=np.zeros(N)\n",
    "    w[0]=lq0(x,u)\n",
    "    L=0\n",
    "    for n in range(N-1):\n",
    "        x,u=flow(x,u,1,prbs,xi,direction='bwd')\n",
    "        L=L+sprbs-np.sum(prbs[x])\n",
    "        w[n+1]=lq0(x,u)-L\n",
    "    # end for\n",
    "    return LogSumExp(w)-np.log(N)\n",
    "\n",
    "def randqN(size,N,randq0):\n",
    "    if N==1: return randq0(size)\n",
    "    K=np.random.randint(low=0,high=N,size=size)\n",
    "    x,u=randq0(size)\n",
    "    for i in range(size): \n",
    "        tx,tu = flow(np.atleast_1d(x[i,...]),np.atleast_1d(u[i,...]),steps=K[i],prbs=prbs,xi=xi,direction='fwd')\n",
    "        x[i,...]=tx\n",
    "        u[i,...]=tu\n",
    "    return x,u\n",
    "    \n",
    "\n",
    "\n",
    "########################################\n",
    "########################################\n",
    "# flow functions\n",
    "########################################\n",
    "########################################\n",
    "def flow(x,u,steps,prbs,xi=np.pi/16,direction='fwd'):\n",
    "    M=prbs.ndim\n",
    "    if steps==0: return x,u\n",
    "    for t in range(steps):\n",
    "        for m in range(M):\n",
    "            m_idx = m if direction=='fwd'else M-m-1 # if in reverse, update starting from the end\n",
    "            #tmp_prbs=np.take(prbs,indices=x[],axis=M-m+1) # TODO HOW TO INDEX?!?!\n",
    "            # TODO IMPROVE THIS BRUTE FORCE SLICING\n",
    "            # we want something like tmp_prbs=prbs[x_1,x_2,...,x_{m-1},:,x_{m+1},...,x_M]\n",
    "            tmp_prbs=np.ones(prbs.shape[m_idx]) # init uniform\n",
    "            tmp_x=np.copy(x)\n",
    "            for i in range(prbs.shape[m_idx]):\n",
    "                tmp_x[m_idx]=i\n",
    "                tmp_prbs[i]=prbs[tuple(tmp_x)]\n",
    "            # END TODO\n",
    "            tx,tu=Tm(x[m_idx],u[m_idx],tmp_prbs/np.sum(tmp_prbs),xi,direction=direction)\n",
    "            x[m_idx]=tx\n",
    "            u[m_idx]=tu\n",
    "        # end for\n",
    "    # end for\n",
    "    return x,u\n",
    "        \n",
    "    \n",
    "def Tm(x,u,prbs,xi=np.pi/16,direction='fwd'):\n",
    "    if direction=='bwd': xi=-xi\n",
    "    p=getp(x,u,prbs,xi)\n",
    "    xp=quantile(p,prbs)\n",
    "    up=(p-cdf(xp-1,prbs))/prbs[xp]\n",
    "    return xp,up\n",
    "\n",
    "\n",
    "def getp(x,u,prbs,xi=np.pi/16):\n",
    "    p=u*prbs[x]\n",
    "    if x>0:  p+=np.sum(prbs[:x])\n",
    "    return (p+xi)%1\n",
    "    \n",
    "########################################\n",
    "########################################\n",
    "# auxiliary functions\n",
    "########################################\n",
    "########################################\n",
    "def LogSumExp(w):\n",
    "    wmax = np.amax(w)\n",
    "    return wmax + np.log(np.sum(np.exp(w-wmax)))\n",
    "def cdf(x,prbs): return np.sum(prbs[:(x+1)])\n",
    "def quantile(u,prbs): return np.argmax(np.cumsum(prbs)>u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5b954",
   "metadata": {},
   "source": [
    "## Univariate example\n",
    "\n",
    "We generate a random probability distribution.\n",
    "Then we run our algorithm for 1,000 iterations and produce some diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12418431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01393119, 0.74289525, 0.16878246, 0.0743911 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the distribution\n",
    "np.random.seed(2022)\n",
    "M=4\n",
    "prbs=np.random.rand(M)\n",
    "prbs=prbs/np.sum(prbs)\n",
    "prbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lq0 = lambda x,u :-np.log(prbs.shape[0])\n",
    "def randq0(size): return np.random.randint(0,prbs.shape[0],size),np.random.rand(size)\n",
    "xi=np.pi/16\n",
    "\n",
    "# params\n",
    "Ns=np.arange(1,101,10)\n",
    "size=100\n",
    "us=np.arange(0.,1.05,0.01)\n",
    "lqs=np.zeros((M,Ns.shape[0]))\n",
    "samples=np.zeros((size,Ns.shape[0]))\n",
    "\n",
    "# get log q's and samples\n",
    "for n in range(Ns.shape[0]):\n",
    "    trx,tru=randqN(size,Ns[n],randq0)\n",
    "    samples[:,n]=trx\n",
    "    for m in range(M):\n",
    "        tmp_lqs=np.zeros(us.shape[0])\n",
    "        for i in range(us.shape[0]):\n",
    "            tmp_lqs[i]=lqN(m*np.ones(1,dtype=int),us[i]*np.ones(1),Ns[n],lq0,prbs,xi)\n",
    "        # end for\n",
    "        lqs[m,n]=np.mean(tmp_lqs) # average over the uniform to marginalize\n",
    "    # end for\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttx=np.arange(0,prbs.shape[0])\n",
    "plt.bar(ttx,prbs, alpha=0.75)\n",
    "for n in range(Ns.shape[0]):\n",
    "    ttprbs=np.exp(lqs[:,n])/np.sum(np.exp(lqs[:,n]))\n",
    "    plt.plot(ttx,ttprbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fbd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(ttx+0.5,prbs, alpha=1)\n",
    "plt.hist(samples[:,-1],density=True,bins=[0,1,2,3,4],alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint=np.zeros((prbs.shape[0],us.shape[0]))\n",
    "for m in range(M):\n",
    "    for i in range(us.shape[0]):\n",
    "        joint[m,i]=lqN(m*np.ones(1,dtype=int),us[i]*np.ones(1),100,lq0,prbs,xi)\n",
    "    # end for\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(joint, cmap='hot', interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e466414",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ttx,np.exp(joint[:,50])/np.sum(np.exp(joint[:,50])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2921cff",
   "metadata": {},
   "source": [
    "### Inversion diagnostic\n",
    "\n",
    "Since this map is easily invertible,\n",
    "we push the final particle back for 1,000 iterations to ensure that it reaches the original point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7484cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward map\n",
    "tu=u[-1]\n",
    "tx=x[-1]\n",
    "print('Final (u,x)=('+str(tu)+','+str(tx+1)+')')\n",
    "for it in range(n_iters):\n",
    "    tx,tu=update(tx,tu,prbs,xi,'bwd')\n",
    "# end for\n",
    "print('Initial (u,x)=('+str(tu)+','+str(tx+1)+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9796b37",
   "metadata": {},
   "source": [
    "We got the same $x$ labels, but the uniform variate is ever so slightly different.\n",
    "In particular, the difference is of the order of $10^{15}$.\n",
    "However, as we'll see later on, these differences add up to big deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58546f",
   "metadata": {},
   "source": [
    "### Uniformity test\n",
    "\n",
    "Here we study the trace of the uniform variate.\n",
    "Notice that there is a clear pattern,\n",
    "which is expected from the simple lcg update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7355cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(np.arange(1,n_iters+1),u[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a13c4",
   "metadata": {},
   "source": [
    "### Quality of empirical approximation\n",
    "\n",
    "Now we estimate the marginal empirical probability distribution of $X$ after all iterations.\n",
    "The final approximation is good,\n",
    "and we note that it doesn't take too long for the probabilities to stabilize around their true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eprbs=plt.hist(x,bins=np.arange(prbs.shape[0]+1),density=True)[0]\n",
    "plt.clf()\n",
    "print('True: '+str(prbs))\n",
    "print('Empirical: '+str(eprbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6239254",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs=np.zeros((int(n_iters/10)-1,prbs.shape[0]))\n",
    "\n",
    "i=0\n",
    "for it in 10*np.arange(1,n_iters/10):\n",
    "    freqs[i,:]=plt.hist(x[:int(it)],bins=np.arange(prbs.shape[0]+1),density=True)[0]\n",
    "    i=i+1\n",
    "plt.clf()\n",
    "\n",
    "colors=['#3F4788','#238A8D','#DCE318','#DD5E66']\n",
    "\n",
    "for n in range(prbs.shape[0]):\n",
    "    plt.plot(10*np.arange(1,n_iters/10),freqs[:,n],c=colors[n], label='P(X='+str(n)+')',ls='dashed')\n",
    "    plt.hlines(prbs[n],0,n_iters,colors=colors[n])\n",
    "# end for\n",
    "plt.xlabel('iter #')\n",
    "plt.ylabel('prob')\n",
    "plt.legend(fontsize='x-small',loc='center right',frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860bbbe",
   "metadata": {},
   "source": [
    "## Bivariate example\n",
    "\n",
    "Now we consider a random 4x4 bivariate density.\n",
    "(As before, we take Trevor's example to compare.)\n",
    "We now run 10,000 iterations of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030caade",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "prbs=np.array([[0.0903257, 0.031233, 0.0648814, 0.0201844],\n",
    " [0.022866, 0.0872383, 0.00311221, 0.0900461],\n",
    " [0.0612982, 0.0145122, 0.03126, 0.120812],\n",
    " [0.13305, 0.0718069, 0.0893575, 0.0680155]]) # trevor's example\n",
    "#prbs=np.random.rand(4,4)\n",
    "prbs=prbs/np.sum(prbs)\n",
    "print(prbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29000bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "n_iters=100000\n",
    "xi=np.pi/16\n",
    "x=np.zeros(n_iters+1,dtype=int)\n",
    "y=np.zeros(n_iters+1,dtype=int)+2\n",
    "u=np.zeros(n_iters+1)\n",
    "v=np.zeros(n_iters+1)\n",
    "u[0]=np.random.rand()\n",
    "v[0]=np.random.rand()\n",
    "u[0]=0.2654657001673143 # trevor's example\n",
    "v[0]=0.40302657652555507 # trevor's example\n",
    "\n",
    "print('Initial (u,x)=('+str(u[0])+','+str(x[0]+1)+')   (v,y)=('+str(v[0])+','+str(y[0]+1)+')')\n",
    "\n",
    "# forward map\n",
    "for it in range(n_iters):\n",
    "    # step in (x,u)\n",
    "    xprbs=prbs[:,y[it]]/np.sum(prbs[:,y[it]])\n",
    "    tmpx,tmpu=update(x[it],u[it],xprbs)\n",
    "    x[it+1]=tmpx\n",
    "    u[it+1]=tmpu\n",
    "    # step in (y,v)\n",
    "    yprbs=prbs[x[it+1],:]/np.sum(prbs[x[it+1],:])\n",
    "    tmpy,tmpv=update(y[it],v[it],yprbs)\n",
    "    y[it+1]=tmpy\n",
    "    v[it+1]=tmpv\n",
    "# end for\n",
    "print('Final (u,x)=('+str(u[-1])+','+str(x[-1]+1)+')   (v,y)=('+str(v[-1])+','+str(y[-1]+1)+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9968586",
   "metadata": {},
   "source": [
    "### Inversion diagnostic\n",
    "\n",
    "As before, we push the final particle through the inverse map for 10,000 iterations.\n",
    "Unlike before, however,\n",
    "we no longer recover the original values!\n",
    "This is probably due to numerical errors&mdash;i.e., instability in the numerical inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward map\n",
    "tu=u[-1]\n",
    "tx=x[-1]\n",
    "tv=v[-1]\n",
    "ty=y[-1]\n",
    "print('Final (u,x)=('+str(tu)+','+str(tx+1)+')   (v,y)=('+str(tv)+','+str(ty+1)+')')\n",
    "for it in range(n_iters):\n",
    "    ty,tv=update(ty,tv,prbs[tx,:]/np.sum(prbs[tx,:]),xi,'bwd')\n",
    "    tx,tu=update(tx,tu,prbs[:,ty]/np.sum(prbs[:,ty]),xi,'bwd')\n",
    "# end for\n",
    "print('Initial (u,x)=('+str(tu)+','+str(tx+1)+')   (v,y)=('+str(tv)+','+str(ty+1)+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a520e",
   "metadata": {},
   "source": [
    "### Uniformity test\n",
    "\n",
    "Here we study the trace of the uniform variate.\n",
    "Interestingly, there no longer appear to be any patterns in the uniform traceplot...\n",
    "Still thinking why this is the case.\n",
    "(This was also true in Trevor's example, btw.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(np.arange(1,n_iters+1),u[1:], label='u', alpha=0.25,s=1)\n",
    "plt.scatter(np.arange(1,n_iters+1),v[1:], label='v', alpha=0.25,s=1)\n",
    "#plt.legend(fontsize='x-small',frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465a118",
   "metadata": {},
   "source": [
    "### Quality of empirical approximation\n",
    "\n",
    "Now we estimate the marginal empirical probability distribution of $(X,Y)$ after all iterations.\n",
    "The final approximation is also good,\n",
    "and we note that it again doesn't take too long for the probabilities to stabilize around their true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32114b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eprbs=plt.hist2d(x,y,bins=[np.arange(prbs.shape[0]+1),np.arange(prbs.shape[1]+1)], density=True)[0]\n",
    "plt.clf()\n",
    "print('True: '+str(prbs))\n",
    "print('Empirical: '+str(eprbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd74761",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize=100\n",
    "xfreqs=np.zeros((int(n_iters/binsize)-1,prbs.shape[0]))\n",
    "yfreqs=np.zeros((int(n_iters/binsize)-1,prbs.shape[0]))\n",
    "\n",
    "i=0\n",
    "for it in binsize*np.arange(1,n_iters/binsize):\n",
    "    xfreqs[i,:]=plt.hist(x[:int(it)],bins=np.arange(prbs.shape[0]+1),density=True)[0]\n",
    "    yfreqs[i,:]=plt.hist(y[:int(it)],bins=np.arange(prbs.shape[0]+1),density=True)[0]\n",
    "    i=i+1\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(prbs.shape[0]):\n",
    "    plt.plot(binsize*np.arange(1,n_iters/binsize),xfreqs[:,n],c=colors[n], label='P(X='+str(n)+')',ls='dashed')\n",
    "    plt.hlines(np.sum(prbs[n,:]),0,n_iters,colors=colors[n])\n",
    "# end for\n",
    "plt.xlabel('iter #')\n",
    "plt.ylabel('prob')\n",
    "plt.legend(fontsize='x-small',loc='center right',frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(prbs.shape[0]):\n",
    "    plt.plot(binsize*np.arange(1,n_iters/binsize),yfreqs[:,n],c=colors[n], label='P(Y='+str(n)+')',ls='dashed')\n",
    "    plt.hlines(np.sum(prbs[:,n]),0,n_iters,colors=colors[n])\n",
    "# end for\n",
    "plt.xlabel('iter #')\n",
    "plt.ylabel('prob')\n",
    "plt.legend(fontsize='x-small',loc='center right',frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
